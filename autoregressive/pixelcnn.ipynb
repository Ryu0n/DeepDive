{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:01<00:00, 7470124.73it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 32828101.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:00<00:00, 4957685.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 17887820.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# 필요한 패키지 import\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# 입력된 데이터를 변환하기 위한 코드\n",
    "# transforms는 여러 transform으로 구성될 수 있음 (리스트로 구성)\n",
    "# PIL 이미지 혹은 numpy 배열(0 ~ 255의 값을 포함)을 torch tensor(0 ~ 1의 값을 포함)으로 변환\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "\n",
    "# 배치 사이즈\n",
    "batch_size = 256\n",
    "\n",
    "# MNIST 데이터셋을 없는 경우 다운로드 (transform 적용)\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "\n",
    "# 위에서 다운로드 받은 데이터셋을 배치 사이즈 단위로 샘플을 묶어 데이터 로더로 변환 (shuffle 과정 포함)\n",
    "# shuffle을 통해 overfitting 방지 가능\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num_pictures = 10\n",
    "plt.figure(figsize=(20, 5))\n",
    "\n",
    "for i in range(num_pictures):\n",
    "\t# i번째 이미지\n",
    "\timg = trainset[i][0]\n",
    "\t\n",
    "\t# (1 x num_pictures) 행의 i번째에 이미지를 출력하기 위함\n",
    "\tax = plt.subplot(1, num_pictures, i+1)\n",
    "\n",
    "\t# x, y 축 안보이게 설정\n",
    "\tax.get_xaxis().set_visible(False)\n",
    "\tax.get_yaxis().set_visible(False)\n",
    "\n",
    "\tplt.imshow(img.cpu().squeeze().numpy(), cmap='gist_gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PixelCNN(\n",
      "  (MaskAConv): Sequential(\n",
      "    (0): MaskedCNN(1, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (MaskBConv): Sequential(\n",
      "    (0): MaskedCNN(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): MaskedCNN(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaskedCNN(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (8): ReLU(inplace=True)\n",
      "    (9): MaskedCNN(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (11): ReLU(inplace=True)\n",
      "    (12): MaskedCNN(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (14): ReLU(inplace=True)\n",
      "    (15): MaskedCNN(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (16): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (17): ReLU(inplace=True)\n",
      "    (18): MaskedCNN(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (19): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (20): ReLU(inplace=True)\n",
      "    (21): MaskedCNN(64, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False)\n",
      "    (22): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (23): ReLU(inplace=True)\n",
      "  )\n",
      "  (out): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "layers = 8\n",
    "kernel = 7\n",
    "channel = 64\n",
    "\n",
    "class MaskedCNN(nn.Conv2d):\n",
    "\tdef __init__(self, mask_type, *args, **kwargs):\n",
    "\t\tself.mask_type = mask_type\n",
    "\n",
    "\t\tassert mask_type in ['A', 'B'], \"Unknown Mask Type\"\n",
    "\n",
    "\t\t# Mask\n",
    "\t\t#         -------------------------------------\n",
    "\t\t#        |  1       1       1       1       1 |\n",
    "\t\t#        |  1       1       1       1       1 |\n",
    "\t\t#        |  1       1    1 if B     0       0 |   H // 2\n",
    "\t\t#        |  0       0       0       0       0 |   H // 2 + 1\n",
    "\t\t#        |  0       0       0       0       0 |\n",
    "\t\t#         -------------------------------------\n",
    "\t\t#  index    0       1     W//2    W//2+1\n",
    "\n",
    "\t\tsuper(MaskedCNN, self).__init__(*args, **kwargs)\n",
    "\t\t\n",
    "\t\t# mask라는 이름의 buffer 생성\n",
    "\t\tself.register_buffer('mask', self.weight.data.clone())\n",
    "\t\t\n",
    "\t\t_, depth, height, width = self.weight.size()\n",
    "\n",
    "\t\t# mask를 1로 채움\n",
    "\t\tself.mask.fill_(1)\n",
    "\n",
    "\t\tif mask_type == 'A':\n",
    "\t\t\tself.mask[:, :, height//2, width//2:] = 0\n",
    "\t\t\tself.mask[:, :, height//2+1:, :] = 0\n",
    "\n",
    "\t\telif mask_type == 'B':\n",
    "\t\t\tself.mask[:, :, height//2, width//2+1] = 0\n",
    "\t\t\tself.mask[:, :, height//2+1:, :] = 0\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\t# Convlution 연산 수행 이전에 마스크 적용\n",
    "\t\tself.weight.data *= self.mask\n",
    "\t\treturn super(MaskedCNN, self).forward(x)\n",
    "\n",
    "\n",
    "class PixelCNN(nn.Module):\n",
    "\tdef __init__(self, no_layers=8, kernel=7, channels=64, device=None):\n",
    "\t\tsuper(PixelCNN, self).__init__()\n",
    "\t\tself.no_layers = no_layers\n",
    "\t\tself.kernel = kernel\n",
    "\t\tself.channels = channels\n",
    "\t\tself.layers = {}\n",
    "\t\tself.device = device\n",
    "\n",
    "\t\tself.MaskAConv = nn.Sequential(\n",
    "\t\t\tMaskedCNN(\n",
    "\t\t\t\tmask_type='A', \n",
    "\t\t\t\tin_channels=1, \n",
    "\t\t\t\tout_channels=channels, \n",
    "\t\t\t\tkernel_size=kernel, \n",
    "\t\t\t\tstride=1, \n",
    "\t\t\t\tpadding=kernel//2, \n",
    "\t\t\t\tbias=False\n",
    "\t\t\t),\n",
    "\t\t\tnn.BatchNorm2d(channels),\n",
    "\t\t\tnn.ReLU(True)\n",
    "\t\t)\n",
    "\n",
    "\t\tMaskBConv = []\n",
    "\t\tfor i in range(8):\n",
    "\t\t\tMaskBConv.append(MaskedCNN('B', channels, channels, kernel, 1, kernel//2, bias=False))\n",
    "\t\t\tMaskBConv.append(nn.BatchNorm2d(channels))\n",
    "\t\t\tMaskBConv.append(nn.ReLU(True))\n",
    "\t\tself.MaskBConv = nn.Sequential(*MaskBConv)\n",
    "\t\tself.out = nn.Conv2d(channels, 256, 1) # 0 ~ 255 logits\n",
    "\n",
    "\tdef forward(self, x):\n",
    "\t\tx = self.MaskAConv(x)\n",
    "\t\tx = self.MaskBConv(x)\n",
    "\t\treturn self.out(x) # (batch_size, 256, height, width)\n",
    "\n",
    "model = PixelCNN().to(device)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "no_images = 5\n",
    "images_size = 28\n",
    "images_channels = 1\n",
    "\n",
    "def sampling():\n",
    "\tmodel.eval()\n",
    "\tsample = torch.Tensor(no_images, images_channels, images_size, images_size).to(device)\n",
    "\tsample.fill_(0) # Fill the tensor with 0\n",
    "\n",
    "\t# Generating images pixel by pixel\n",
    "\tfor i in range(images_size):\n",
    "\t\tfor j in range(images_size):\n",
    "\t\t\tout = model(sample)\n",
    "\t\t\tprobs = F.softmax(out[:, :, i, j], dim=-1).data # 256 logit values per pixel\n",
    "\t\t\t\n",
    "\t\t\t# (i, j)번째에는 0값부터 255까지 나올 수 있는 확률들이 존재한다.\n",
    "\t\t\t# 255개의 확률 값들을 확률 분포로 해석하여 1개를 샘플링 한다.\n",
    "\t\t\t# 샘플링된 인덱스가 나오고 이것을 255를 max값으로 가정하고 정규화한다.\n",
    "\t\t\tsample[:, :, i, j] = torch.multinomial(input=probs, num_samples=1).float() / 255.0\n",
    "\n",
    "\tplt.figure(figsize=(10, 10))\n",
    "\tfor i in range(no_images):\n",
    "\t\tax = plt.subplot(1, no_images, i+1)\n",
    "\t\tax.get_xaxis().set_visible(False)\n",
    "\t\tax.get_yaxis().set_visible(False)\n",
    "\t\tplt.imshow(transforms.ToPILImage()(sample[i, :, :, :]), interplation=\"bicubic\", cmap=\"gist_gray\")\n",
    "\tplt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch : 1 of 100, loss : 5.620:   0%|          | 1/234 [01:00<3:54:45, 60.45s/it]"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs = 100\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "\tmodel.train()\n",
    "\trunning_loss = 0.0\n",
    "\n",
    "\t# pbar 길이 : batch 갯수\n",
    "\tpbar = tqdm(enumerate(trainloader, 0), total=int(len(trainset) / trainloader.batch_size))\n",
    "\n",
    "\tfor i, data in pbar:\n",
    "\t\t# input tensor : (batch_size, channels, height, width)\n",
    "\t\tinputs, _ = data\n",
    "\t\ttarget = (inputs[:, 0, :, :] * 255).long()\n",
    "\t\t\n",
    "\t\tinputs = inputs.to(device)\n",
    "\t\ttarget = target.to(device)\n",
    "\n",
    "\t\toptimizer.zero_grad()\n",
    "\t\t\n",
    "\t\toutputs = model(inputs)\n",
    "\t\t# outputs : (batch_size, 256, height, width) -> logits\n",
    "\t\t# target : (batch_size, 1, height, width) -> label\n",
    "\t\tloss = criterion(outputs, target)\n",
    "\t\tloss.backward()\n",
    "\t\toptimizer.step()\n",
    "\n",
    "\t\trunning_loss += loss.item()\n",
    "\t\tpbar.set_description(f'epoch : {epoch + 1} of {num_epochs}, loss : {running_loss / (i+1):.3f}')\n",
    "\n",
    "\tsampling()\n",
    "\n",
    "print('Training Finished')\t\t\n",
    "\n",
    "PATH = './savedModel.pth'\n",
    "torch.save(model.state_dict(), PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DeepImplement",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
