{
  "cells": [
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "dpW1ykkEHlP3"
      },
      "source": [
        "# magenta 환경 설정  \n",
        "- 로컬 환경과 Colab 환경을 통해 `pip install magenta` 혹은 `curl`을 통한 자동 설치는 호환성 측면에서 많은 문제가 발생했다. (필자의 노트북은 M1 Pro)\n",
        "\n",
        "[docker 컨테이너를 활용한 방법](https://www.notion.so/docker-6d34d8cbaf184fc3a77088349644ac49)\n",
        "\n",
        "[Colab 환경 구성](https://www.notion.so/Colab-d804958ce7a14faeaac56b9fb39b2ac7)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "FvdoVSzBcgJf",
        "outputId": "3c277ed7-26fc-40dc-9713-a86e7f4dc65c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting hmmlearn\n",
            "  Downloading hmmlearn-0.3.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (160 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m160.4/160.4 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.10 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.22.4)\n",
            "Requirement already satisfied: scikit-learn!=0.22.0,>=0.16 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.2.2)\n",
            "Requirement already satisfied: scipy>=0.19 in /usr/local/lib/python3.10/dist-packages (from hmmlearn) (1.10.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn!=0.22.0,>=0.16->hmmlearn) (3.1.0)\n",
            "Installing collected packages: hmmlearn\n",
            "Successfully installed hmmlearn-0.3.0\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu focal-cran40/ InRelease [3,622 B]\n",
            "Get:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  InRelease [1,581 B]\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2004/x86_64  Packages [1,011 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu focal-security InRelease [114 kB]\n",
            "Hit:5 http://archive.ubuntu.com/ubuntu focal InRelease\n",
            "Get:6 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal InRelease [18.1 kB]\n",
            "Get:7 http://archive.ubuntu.com/ubuntu focal-updates InRelease [114 kB]\n",
            "Hit:8 http://ppa.launchpad.net/cran/libgit2/ubuntu focal InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu focal-security/main amd64 Packages [2,773 kB]\n",
            "Hit:10 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu focal InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu focal-backports InRelease [108 kB]\n",
            "Hit:12 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu focal InRelease\n",
            "Get:13 http://archive.ubuntu.com/ubuntu focal-updates/main amd64 Packages [3,252 kB]\n",
            "Hit:14 http://ppa.launchpad.net/ubuntugis/ppa/ubuntu focal InRelease\n",
            "Get:15 http://security.ubuntu.com/ubuntu focal-security/restricted amd64 Packages [2,345 kB]\n",
            "Get:16 http://security.ubuntu.com/ubuntu focal-security/universe amd64 Packages [1,056 kB]\n",
            "Get:17 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main Sources [2,584 kB]\n",
            "Get:18 http://archive.ubuntu.com/ubuntu focal-updates/universe amd64 Packages [1,351 kB]\n",
            "Get:19 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu focal/main amd64 Packages [1,219 kB]\n",
            "Fetched 15.9 MB in 5s (2,963 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "python3.8 is already the newest version (3.8.10-0ubuntu1~20.04.7).\n",
            "python3.8 set to manually installed.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 40 not upgraded.\n",
            "update-alternatives: using /usr/bin/python3.8 to provide /usr/bin/python3 (python3) in manual mode\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100 2518k  100 2518k    0     0  37.8M      0 --:--:-- --:--:-- --:--:-- 37.8M\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pip\n",
            "  Downloading pip-23.1.2-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting setuptools\n",
            "  Downloading setuptools-67.8.0-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wheel\n",
            "  Downloading wheel-0.40.0-py3-none-any.whl (64 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.5/64.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: wheel, setuptools, pip\n",
            "Successfully installed pip-23.1.2 setuptools-67.8.0 wheel-0.40.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numba==0.48\n",
            "  Downloading numba-0.48.0-1-cp38-cp38-manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m86.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llvmlite<0.32.0,>=0.31.0dev0 (from numba==0.48)\n",
            "  Downloading llvmlite-0.31.0-cp38-cp38-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy>=1.15 (from numba==0.48)\n",
            "  Downloading numpy-1.24.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.3/17.3 MB\u001b[0m \u001b[31m66.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba==0.48) (67.8.0)\n",
            "Installing collected packages: llvmlite, numpy, numba\n",
            "Successfully installed llvmlite-0.31.0 numba-0.48.0 numpy-1.24.3\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting numpy==1.23\n",
            "  Downloading numpy-1.23.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.24.3\n",
            "    Uninstalling numpy-1.24.3:\n",
            "      Successfully uninstalled numpy-1.24.3\n",
            "Successfully installed numpy-1.23.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0mLooking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting librosa==0.7.2\n",
            "  Downloading librosa-0.7.2.tar.gz (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting audioread>=2.0.0 (from librosa==0.7.2)\n",
            "  Downloading audioread-3.0.0.tar.gz (377 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.0/377.0 kB\u001b[0m \u001b[31m46.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: numpy>=1.15.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2) (1.23.0)\n",
            "Collecting scipy>=1.0.0 (from librosa==0.7.2)\n",
            "  Downloading scipy-1.10.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (34.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m34.5/34.5 MB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn!=0.19.0,>=0.14.0 (from librosa==0.7.2)\n",
            "  Downloading scikit_learn-1.2.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.8/9.8 MB\u001b[0m \u001b[31m62.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=0.12 (from librosa==0.7.2)\n",
            "  Downloading joblib-1.2.0-py3-none-any.whl (297 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m298.0/298.0 kB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting decorator>=3.0.0 (from librosa==0.7.2)\n",
            "  Downloading decorator-5.1.1-py3-none-any.whl (9.1 kB)\n",
            "Collecting six>=1.3 (from librosa==0.7.2)\n",
            "  Downloading six-1.16.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting resampy>=0.2.2 (from librosa==0.7.2)\n",
            "  Downloading resampy-0.4.2-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m74.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numba>=0.43.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2) (0.48.0)\n",
            "Collecting soundfile>=0.9.0 (from librosa==0.7.2)\n",
            "  Downloading soundfile-0.12.1-py2.py3-none-manylinux_2_31_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.32.0,>=0.31.0dev0 in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa==0.7.2) (0.31.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba>=0.43.0->librosa==0.7.2) (67.8.0)\n",
            "Collecting numba>=0.43.0 (from librosa==0.7.2)\n",
            "  Downloading numba-0.57.0-cp38-cp38-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m123.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting llvmlite<0.41,>=0.40.0dev0 (from numba>=0.43.0->librosa==0.7.2)\n",
            "  Downloading llvmlite-0.40.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (42.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.1/42.1 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-metadata (from numba>=0.43.0->librosa==0.7.2)\n",
            "  Downloading importlib_metadata-6.6.0-py3-none-any.whl (22 kB)\n",
            "Collecting threadpoolctl>=2.0.0 (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.7.2)\n",
            "  Downloading threadpoolctl-3.1.0-py3-none-any.whl (14 kB)\n",
            "Collecting cffi>=1.0 (from soundfile>=0.9.0->librosa==0.7.2)\n",
            "  Downloading cffi-1.15.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (442 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m442.7/442.7 kB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pycparser (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2)\n",
            "  Downloading pycparser-2.21-py2.py3-none-any.whl (118 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m118.7/118.7 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting zipp>=0.5 (from importlib-metadata->numba>=0.43.0->librosa==0.7.2)\n",
            "  Downloading zipp-3.15.0-py3-none-any.whl (6.8 kB)\n",
            "Building wheels for collected packages: librosa, audioread\n",
            "  Building wheel for librosa (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for librosa: filename=librosa-0.7.2-py3-none-any.whl size=1612885 sha256=969d2ecce1e2f74cbc67c29f9a9e3408fff42beac7a74a3ccba5b1dd42b1009d\n",
            "  Stored in directory: /root/.cache/pip/wheels/11/f0/b0/a8f9944f274bbc0f0159f2268f43dadcfa1cfe50a9007d8e1f\n",
            "  Building wheel for audioread (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for audioread: filename=audioread-3.0.0-py3-none-any.whl size=23706 sha256=041b650aab5545ab2b33b90cd45ca29da0d8872ced66b99a6ca734a3e7aa1bc6\n",
            "  Stored in directory: /root/.cache/pip/wheels/0a/ed/be/49df2538fca496690a024a4374455584d65c2afd6fc3d6e9c7\n",
            "Successfully built librosa audioread\n",
            "Installing collected packages: zipp, threadpoolctl, six, scipy, pycparser, llvmlite, joblib, decorator, audioread, scikit-learn, importlib-metadata, cffi, soundfile, numba, resampy, librosa\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.31.0\n",
            "    Uninstalling llvmlite-0.31.0:\n",
            "      Successfully uninstalled llvmlite-0.31.0\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.48.0\n",
            "    Uninstalling numba-0.48.0:\n",
            "      Successfully uninstalled numba-0.48.0\n",
            "Successfully installed audioread-3.0.0 cffi-1.15.1 decorator-5.1.1 importlib-metadata-6.6.0 joblib-1.2.0 librosa-0.7.2 llvmlite-0.40.0 numba-0.57.0 pycparser-2.21 resampy-0.4.2 scikit-learn-1.2.2 scipy-1.10.1 six-1.16.0 soundfile-0.12.1 threadpoolctl-3.1.0 zipp-3.15.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cffi",
                  "six"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting magenta\n",
            "  Downloading magenta-2.1.4-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m57.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting absl-py==1.2.0 (from magenta)\n",
            "  Downloading absl_py-1.2.0-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.4/123.4 kB\u001b[0m \u001b[31m19.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting dm-sonnet==2.0.0 (from magenta)\n",
            "  Downloading dm_sonnet-2.0.0-py3-none-any.whl (254 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m254.5/254.5 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting imageio==2.20.0 (from magenta)\n",
            "  Downloading imageio-2.20.0-py3-none-any.whl (3.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.4/3.4 MB\u001b[0m \u001b[31m37.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: librosa==0.7.2 in /usr/local/lib/python3.8/dist-packages (from magenta) (0.7.2)\n",
            "Collecting matplotlib==3.5.2 (from magenta)\n",
            "  Downloading matplotlib-3.5.2-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (11.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m85.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mido==1.2.6 (from magenta)\n",
            "  Downloading mido-1.2.6-py2.py3-none-any.whl (69 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m69.8/69.8 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting mir-eval==0.7 (from magenta)\n",
            "  Downloading mir_eval-0.7.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.7/90.7 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting note-seq==0.0.3 (from magenta)\n",
            "  Downloading note_seq-0.0.3-py3-none-any.whl (210 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.1/210.1 kB\u001b[0m \u001b[31m30.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numba==0.49.1 (from magenta)\n",
            "  Downloading numba-0.49.1-cp38-cp38-manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m99.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting numpy==1.21.6 (from magenta)\n",
            "  Downloading numpy-1.21.6-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.7/15.7 MB\u001b[0m \u001b[31m81.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting Pillow==9.2.0 (from magenta)\n",
            "  Downloading Pillow-9.2.0-cp38-cp38-manylinux_2_28_x86_64.whl (3.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.2/3.2 MB\u001b[0m \u001b[31m105.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pretty-midi==0.2.9 (from magenta)\n",
            "  Downloading pretty_midi-0.2.9.tar.gz (5.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m106.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting pygtrie==2.5.0 (from magenta)\n",
            "  Downloading pygtrie-2.5.0-py3-none-any.whl (25 kB)\n",
            "Collecting python-rtmidi==1.1.2 (from magenta)\n",
            "  Downloading python-rtmidi-1.1.2.tar.gz (204 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m204.5/204.5 kB\u001b[0m \u001b[31m29.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting scikit-image==0.19.3 (from magenta)\n",
            "  Downloading scikit_image-0.19.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (14.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.0/14.0 MB\u001b[0m \u001b[31m71.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scipy==1.7.3 (from magenta)\n",
            "  Downloading scipy-1.7.3-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (39.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m39.3/39.3 MB\u001b[0m \u001b[31m10.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: six==1.16.0 in /usr/local/lib/python3.8/dist-packages (from magenta) (1.16.0)\n",
            "Collecting sk-video==1.1.10 (from magenta)\n",
            "  Downloading sk_video-1.1.10-py2.py3-none-any.whl (2.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m73.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sox==1.4.1 (from magenta)\n",
            "  Downloading sox-1.4.1-py2.py3-none-any.whl (39 kB)\n",
            "Collecting tensorflow==2.9.1 (from magenta)\n",
            "  Downloading tensorflow-2.9.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (511.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m511.7/511.7 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-datasets==4.6.0 (from magenta)\n",
            "  Downloading tensorflow_datasets-4.6.0-py3-none-any.whl (4.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.3/4.3 MB\u001b[0m \u001b[31m96.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-probability==0.17.0 (from magenta)\n",
            "  Downloading tensorflow_probability-0.17.0-py2.py3-none-any.whl (6.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.5/6.5 MB\u001b[0m \u001b[31m95.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tf-slim==1.1.0 (from magenta)\n",
            "  Downloading tf_slim-1.1.0-py2.py3-none-any.whl (352 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m352.1/352.1 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wheel==0.37.1 (from magenta)\n",
            "  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
            "Collecting dm-tree>=0.1.1 (from dm-sonnet==2.0.0->magenta)\n",
            "  Downloading dm_tree-0.1.8-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m14.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wrapt>=1.11.1 (from dm-sonnet==2.0.0->magenta)\n",
            "  Downloading wrapt-1.15.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.5/81.5 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tabulate>=0.7.5 (from dm-sonnet==2.0.0->magenta)\n",
            "  Downloading tabulate-0.9.0-py3-none-any.whl (35 kB)\n",
            "Requirement already satisfied: audioread>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta) (3.0.0)\n",
            "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta) (1.2.2)\n",
            "Requirement already satisfied: joblib>=0.12 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta) (1.2.0)\n",
            "Requirement already satisfied: decorator>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta) (5.1.1)\n",
            "Requirement already satisfied: resampy>=0.2.2 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta) (0.4.2)\n",
            "Requirement already satisfied: soundfile>=0.9.0 in /usr/local/lib/python3.8/dist-packages (from librosa==0.7.2->magenta) (0.12.1)\n",
            "Collecting cycler>=0.10 (from matplotlib==3.5.2->magenta)\n",
            "  Downloading cycler-0.11.0-py3-none-any.whl (6.4 kB)\n",
            "Collecting fonttools>=4.22.0 (from matplotlib==3.5.2->magenta)\n",
            "  Downloading fonttools-4.39.4-py3-none-any.whl (1.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m55.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting kiwisolver>=1.0.1 (from matplotlib==3.5.2->magenta)\n",
            "  Downloading kiwisolver-1.4.4-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.whl (1.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m60.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.8/dist-packages (from matplotlib==3.5.2->magenta) (23.1)\n",
            "Collecting pyparsing>=2.2.1 (from matplotlib==3.5.2->magenta)\n",
            "  Downloading pyparsing-3.0.9-py3-none-any.whl (98 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.3/98.3 kB\u001b[0m \u001b[31m13.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.7 (from matplotlib==3.5.2->magenta)\n",
            "  Downloading python_dateutil-2.8.2-py2.py3-none-any.whl (247 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m247.7/247.7 kB\u001b[0m \u001b[31m28.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting future (from mir-eval==0.7->magenta)\n",
            "  Downloading future-0.18.3.tar.gz (840 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m840.9/840.9 kB\u001b[0m \u001b[31m50.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting attrs (from note-seq==0.0.3->magenta)\n",
            "  Downloading attrs-23.1.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting bokeh>=0.12.0 (from note-seq==0.0.3->magenta)\n",
            "  Downloading bokeh-3.1.1-py3-none-any.whl (8.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m101.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting intervaltree>=2.1.0 (from note-seq==0.0.3->magenta)\n",
            "  Downloading intervaltree-3.1.0.tar.gz (32 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting IPython (from note-seq==0.0.3->magenta)\n",
            "  Downloading ipython-8.12.2-py3-none-any.whl (797 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m797.8/797.8 kB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pandas>=0.18.1 (from note-seq==0.0.3->magenta)\n",
            "  Downloading pandas-2.0.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (12.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m50.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf>=3.6.1 (from note-seq==0.0.3->magenta)\n",
            "  Downloading protobuf-4.23.2-cp37-abi3-manylinux2014_x86_64.whl (304 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m304.5/304.5 kB\u001b[0m \u001b[31m32.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydub (from note-seq==0.0.3->magenta)\n",
            "  Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
            "Collecting llvmlite<=0.33.0.dev0,>=0.31.0.dev0 (from numba==0.49.1->magenta)\n",
            "  Downloading llvmlite-0.32.1-cp38-cp38-manylinux1_x86_64.whl (20.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.2/20.2 MB\u001b[0m \u001b[31m72.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from numba==0.49.1->magenta) (67.8.0)\n",
            "Collecting networkx>=2.2 (from scikit-image==0.19.3->magenta)\n",
            "  Downloading networkx-3.1-py3-none-any.whl (2.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m93.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tifffile>=2019.7.26 (from scikit-image==0.19.3->magenta)\n",
            "  Downloading tifffile-2023.4.12-py3-none-any.whl (219 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m219.4/219.4 kB\u001b[0m \u001b[31m27.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyWavelets>=1.1.1 (from scikit-image==0.19.3->magenta)\n",
            "  Downloading PyWavelets-1.4.1-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m59.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting astunparse>=1.6.0 (from tensorflow==2.9.1->magenta)\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting flatbuffers<2,>=1.12 (from tensorflow==2.9.1->magenta)\n",
            "  Downloading flatbuffers-1.12-py2.py3-none-any.whl (15 kB)\n",
            "Collecting gast<=0.4.0,>=0.2.1 (from tensorflow==2.9.1->magenta)\n",
            "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
            "Collecting google-pasta>=0.1.1 (from tensorflow==2.9.1->magenta)\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting grpcio<2.0,>=1.24.3 (from tensorflow==2.9.1->magenta)\n",
            "  Downloading grpcio-1.54.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (5.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.1/5.1 MB\u001b[0m \u001b[31m116.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h5py>=2.9.0 (from tensorflow==2.9.1->magenta)\n",
            "  Downloading h5py-3.8.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (4.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.7/4.7 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1->magenta)\n",
            "  Downloading keras-2.9.0-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m73.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting keras-preprocessing>=1.1.1 (from tensorflow==2.9.1->magenta)\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting libclang>=13.0.0 (from tensorflow==2.9.1->magenta)\n",
            "  Downloading libclang-16.0.0-py2.py3-none-manylinux2010_x86_64.whl (22.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m22.9/22.9 MB\u001b[0m \u001b[31m46.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting opt-einsum>=2.3.2 (from tensorflow==2.9.1->magenta)\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting protobuf>=3.6.1 (from note-seq==0.0.3->magenta)\n",
            "  Downloading protobuf-3.19.6-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard<2.10,>=2.9 (from tensorflow==2.9.1->magenta)\n",
            "  Downloading tensorboard-2.9.1-py3-none-any.whl (5.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-io-gcs-filesystem>=0.23.1 (from tensorflow==2.9.1->magenta)\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.32.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m73.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-estimator<2.10.0,>=2.9.0rc0 (from tensorflow==2.9.1->magenta)\n",
            "  Downloading tensorflow_estimator-2.9.0-py2.py3-none-any.whl (438 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow==2.9.1->magenta)\n",
            "  Downloading termcolor-2.3.0-py3-none-any.whl (6.9 kB)\n",
            "Collecting typing-extensions>=3.6.6 (from tensorflow==2.9.1->magenta)\n",
            "  Downloading typing_extensions-4.6.3-py3-none-any.whl (31 kB)\n",
            "Collecting dill (from tensorflow-datasets==4.6.0->magenta)\n",
            "  Downloading dill-0.3.6-py3-none-any.whl (110 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting etils[epath] (from tensorflow-datasets==4.6.0->magenta)\n",
            "  Downloading etils-1.3.0-py3-none-any.whl (126 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m126.4/126.4 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting promise (from tensorflow-datasets==4.6.0->magenta)\n",
            "  Downloading promise-2.3.tar.gz (19 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting requests>=2.19.0 (from tensorflow-datasets==4.6.0->magenta)\n",
            "  Downloading requests-2.31.0-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.6/62.6 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorflow-metadata (from tensorflow-datasets==4.6.0->magenta)\n",
            "  Downloading tensorflow_metadata-1.13.1-py3-none-any.whl (28 kB)\n",
            "Collecting toml (from tensorflow-datasets==4.6.0->magenta)\n",
            "  Downloading toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
            "Collecting tqdm (from tensorflow-datasets==4.6.0->magenta)\n",
            "  Downloading tqdm-4.65.0-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.1/77.1 kB\u001b[0m \u001b[31m11.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting importlib-resources (from tensorflow-datasets==4.6.0->magenta)\n",
            "  Downloading importlib_resources-5.12.0-py3-none-any.whl (36 kB)\n",
            "Collecting cloudpickle>=1.3 (from tensorflow-probability==0.17.0->magenta)\n",
            "  Downloading cloudpickle-2.2.1-py3-none-any.whl (25 kB)\n",
            "Collecting Jinja2>=2.9 (from bokeh>=0.12.0->note-seq==0.0.3->magenta)\n",
            "  Downloading Jinja2-3.1.2-py3-none-any.whl (133 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.1/133.1 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting contourpy>=1 (from bokeh>=0.12.0->note-seq==0.0.3->magenta)\n",
            "  Downloading contourpy-1.0.7-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (300 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m300.0/300.0 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting PyYAML>=3.10 (from bokeh>=0.12.0->note-seq==0.0.3->magenta)\n",
            "  Downloading PyYAML-6.0-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (701 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m701.2/701.2 kB\u001b[0m \u001b[31m60.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tornado>=5.1 (from bokeh>=0.12.0->note-seq==0.0.3->magenta)\n",
            "  Downloading tornado-6.3.2-cp38-abi3-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (426 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m426.9/426.9 kB\u001b[0m \u001b[31m43.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting xyzservices>=2021.09.1 (from bokeh>=0.12.0->note-seq==0.0.3->magenta)\n",
            "  Downloading xyzservices-2023.5.0-py3-none-any.whl (56 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.5/56.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sortedcontainers<3.0,>=2.0 (from intervaltree>=2.1.0->note-seq==0.0.3->magenta)\n",
            "  Downloading sortedcontainers-2.4.0-py2.py3-none-any.whl (29 kB)\n",
            "Collecting pytz>=2020.1 (from pandas>=0.18.1->note-seq==0.0.3->magenta)\n",
            "  Downloading pytz-2023.3-py2.py3-none-any.whl (502 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m502.3/502.3 kB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tzdata>=2022.1 (from pandas>=0.18.1->note-seq==0.0.3->magenta)\n",
            "  Downloading tzdata-2023.3-py2.py3-none-any.whl (341 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m341.8/341.8 kB\u001b[0m \u001b[31m42.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting charset-normalizer<4,>=2 (from requests>=2.19.0->tensorflow-datasets==4.6.0->magenta)\n",
            "  Downloading charset_normalizer-3.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (195 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m195.9/195.9 kB\u001b[0m \u001b[31m25.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting idna<4,>=2.5 (from requests>=2.19.0->tensorflow-datasets==4.6.0->magenta)\n",
            "  Downloading idna-3.4-py3-none-any.whl (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.5/61.5 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting urllib3<3,>=1.21.1 (from requests>=2.19.0->tensorflow-datasets==4.6.0->magenta)\n",
            "  Downloading urllib3-2.0.2-py3-none-any.whl (123 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m123.2/123.2 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting certifi>=2017.4.17 (from requests>=2.19.0->tensorflow-datasets==4.6.0->magenta)\n",
            "  Downloading certifi-2023.5.7-py3-none-any.whl (156 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.0/157.0 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of resampy to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting resampy>=0.2.2 (from librosa==0.7.2->magenta)\n",
            "  Downloading resampy-0.4.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m96.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading resampy-0.4.0-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Downloading resampy-0.3.1-py3-none-any.whl (3.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa==0.7.2->magenta) (3.1.0)\n",
            "Requirement already satisfied: cffi>=1.0 in /usr/local/lib/python3.8/dist-packages (from soundfile>=0.9.0->librosa==0.7.2->magenta) (1.15.1)\n",
            "Collecting google-auth<3,>=1.6.3 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta)\n",
            "  Downloading google_auth-2.19.1-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting google-auth-oauthlib<0.5,>=0.4.1 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta)\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting markdown>=2.6.8 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta)\n",
            "  Downloading Markdown-3.4.3-py3-none-any.whl (93 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-data-server<0.7.0,>=0.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta)\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-manylinux2010_x86_64.whl (4.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m78.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting tensorboard-plugin-wit>=1.6.0 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta)\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m781.3/781.3 kB\u001b[0m \u001b[31m62.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting werkzeug>=1.0.1 (from tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta)\n",
            "  Downloading Werkzeug-2.3.4-py3-none-any.whl (242 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m242.5/242.5 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: zipp in /usr/local/lib/python3.8/dist-packages (from etils[epath]->tensorflow-datasets==4.6.0->magenta) (3.15.0)\n",
            "Collecting backcall (from IPython->note-seq==0.0.3->magenta)\n",
            "  Downloading backcall-0.2.0-py2.py3-none-any.whl (11 kB)\n",
            "Collecting jedi>=0.16 (from IPython->note-seq==0.0.3->magenta)\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m74.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting matplotlib-inline (from IPython->note-seq==0.0.3->magenta)\n",
            "  Downloading matplotlib_inline-0.1.6-py3-none-any.whl (9.4 kB)\n",
            "Collecting pickleshare (from IPython->note-seq==0.0.3->magenta)\n",
            "  Downloading pickleshare-0.7.5-py2.py3-none-any.whl (6.9 kB)\n",
            "Collecting prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30 (from IPython->note-seq==0.0.3->magenta)\n",
            "  Downloading prompt_toolkit-3.0.38-py3-none-any.whl (385 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m385.8/385.8 kB\u001b[0m \u001b[31m34.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pygments>=2.4.0 (from IPython->note-seq==0.0.3->magenta)\n",
            "  Downloading Pygments-2.15.1-py3-none-any.whl (1.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting stack-data (from IPython->note-seq==0.0.3->magenta)\n",
            "  Downloading stack_data-0.6.2-py3-none-any.whl (24 kB)\n",
            "Collecting traitlets>=5 (from IPython->note-seq==0.0.3->magenta)\n",
            "  Downloading traitlets-5.9.0-py3-none-any.whl (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.4/117.4 kB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pexpect>4.3 (from IPython->note-seq==0.0.3->magenta)\n",
            "  Downloading pexpect-4.8.0-py2.py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.0/59.0 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting googleapis-common-protos<2,>=1.52.0 (from tensorflow-metadata->tensorflow-datasets==4.6.0->magenta)\n",
            "  Downloading googleapis_common_protos-1.59.0-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m29.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hINFO: pip is looking at multiple versions of tensorflow-metadata to determine which version is compatible with other requirements. This could take a while.\n",
            "Collecting tensorflow-metadata (from tensorflow-datasets==4.6.0->magenta)\n",
            "  Downloading tensorflow_metadata-1.13.0-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.3/53.3 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pycparser in /usr/local/lib/python3.8/dist-packages (from cffi>=1.0->soundfile>=0.9.0->librosa==0.7.2->magenta) (2.21)\n",
            "Collecting cachetools<6.0,>=2.0.0 (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta)\n",
            "  Downloading cachetools-5.3.1-py3-none-any.whl (9.3 kB)\n",
            "Collecting pyasn1-modules>=0.2.1 (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta)\n",
            "  Downloading pyasn1_modules-0.3.0-py2.py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.3/181.3 kB\u001b[0m \u001b[31m24.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting rsa<5,>=3.1.4 (from google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta)\n",
            "  Downloading rsa-4.9-py3-none-any.whl (34 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests>=2.19.0->tensorflow-datasets==4.6.0->magenta)\n",
            "  Downloading urllib3-1.26.16-py2.py3-none-any.whl (143 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.1/143.1 kB\u001b[0m \u001b[31m24.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting requests-oauthlib>=0.7.0 (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta)\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting parso<0.9.0,>=0.8.0 (from jedi>=0.16->IPython->note-seq==0.0.3->magenta)\n",
            "  Downloading parso-0.8.3-py2.py3-none-any.whl (100 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.8/100.8 kB\u001b[0m \u001b[31m15.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting MarkupSafe>=2.0 (from Jinja2>=2.9->bokeh>=0.12.0->note-seq==0.0.3->magenta)\n",
            "  Downloading MarkupSafe-2.1.2-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (25 kB)\n",
            "Requirement already satisfied: importlib-metadata>=4.4 in /usr/local/lib/python3.8/dist-packages (from markdown>=2.6.8->tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta) (6.6.0)\n",
            "Collecting ptyprocess>=0.5 (from pexpect>4.3->IPython->note-seq==0.0.3->magenta)\n",
            "  Downloading ptyprocess-0.7.0-py2.py3-none-any.whl (13 kB)\n",
            "Collecting wcwidth (from prompt-toolkit!=3.0.37,<3.1.0,>=3.0.30->IPython->note-seq==0.0.3->magenta)\n",
            "  Downloading wcwidth-0.2.6-py2.py3-none-any.whl (29 kB)\n",
            "Collecting executing>=1.2.0 (from stack-data->IPython->note-seq==0.0.3->magenta)\n",
            "  Downloading executing-1.2.0-py2.py3-none-any.whl (24 kB)\n",
            "Collecting asttokens>=2.1.0 (from stack-data->IPython->note-seq==0.0.3->magenta)\n",
            "  Downloading asttokens-2.2.1-py2.py3-none-any.whl (26 kB)\n",
            "Collecting pure-eval (from stack-data->IPython->note-seq==0.0.3->magenta)\n",
            "  Downloading pure_eval-0.2.2-py3-none-any.whl (11 kB)\n",
            "Collecting pyasn1<0.6.0,>=0.4.6 (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta)\n",
            "  Downloading pyasn1-0.5.0-py2.py3-none-any.whl (83 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.9/83.9 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting oauthlib>=3.0.0 (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.10,>=2.9->tensorflow==2.9.1->magenta)\n",
            "  Downloading oauthlib-3.2.2-py3-none-any.whl (151 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m151.7/151.7 kB\u001b[0m \u001b[31m22.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: mir-eval, pretty-midi, python-rtmidi, intervaltree, future, promise\n",
            "  Building wheel for mir-eval (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mir-eval: filename=mir_eval-0.7-py3-none-any.whl size=100705 sha256=3777b9e026dec15ca9788033d6c6c30224335a0706c866b352b77218065b6740\n",
            "  Stored in directory: /root/.cache/pip/wheels/20/53/83/1d50d15a666140d53eda589db005f7cb53b739c7e54711f51f\n",
            "  Building wheel for pretty-midi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretty-midi: filename=pretty_midi-0.2.9-py3-none-any.whl size=5591938 sha256=fbcf5cb5a31313be9e5cfa5ab32b0482b925a3ecb855dbf3d07e92972b1deaa9\n",
            "  Stored in directory: /root/.cache/pip/wheels/2a/5a/e3/30eeb9a99350f3f7e21258fcb132743eef1a4f49b3505e76b6\n",
            "  Building wheel for python-rtmidi (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for python-rtmidi: filename=python_rtmidi-1.1.2-cp38-cp38-linux_x86_64.whl size=591311 sha256=a1b20cf2b71c672003a2351db1859f353f15c2ef423046a478a67745a03f8cd6\n",
            "  Stored in directory: /root/.cache/pip/wheels/23/93/e9/7d805b982c4cb5c6cec3e77e1fc6e7417a193beca2230cea52\n",
            "  Building wheel for intervaltree (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for intervaltree: filename=intervaltree-3.1.0-py2.py3-none-any.whl size=26099 sha256=24cacd8558eb69cb1648e94dd0b3db9b1886d1fa993967084bf7e7dbced0c78b\n",
            "  Stored in directory: /root/.cache/pip/wheels/45/23/de/5789a92962483fd33cb06674792b9697c1b3766d7c7742830e\n",
            "  Building wheel for future (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for future: filename=future-0.18.3-py3-none-any.whl size=492022 sha256=5db0cec5ac3e6a25ed17501063029ddc53f6d480b9dd63643f3c0e3a8f5d27d4\n",
            "  Stored in directory: /root/.cache/pip/wheels/a0/0b/ee/e6994fadb42c1354dcccb139b0bf2795271bddfe6253ccdf11\n",
            "  Building wheel for promise (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for promise: filename=promise-2.3-py3-none-any.whl size=21484 sha256=072421ab770e67087ce829fa7e8958d9fd4ad31935eec790e68551368e592589\n",
            "  Stored in directory: /root/.cache/pip/wheels/54/aa/01/724885182f93150035a2a91bce34a12877e8067a97baaf5dc8\n",
            "Successfully built mir-eval pretty-midi python-rtmidi intervaltree future promise\n",
            "Installing collected packages: wcwidth, tensorboard-plugin-wit, sortedcontainers, pytz, python-rtmidi, pygtrie, pydub, pure-eval, ptyprocess, pickleshare, mido, llvmlite, libclang, keras, flatbuffers, executing, dm-tree, backcall, xyzservices, wrapt, wheel, urllib3, tzdata, typing-extensions, traitlets, tqdm, tornado, toml, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, tensorboard-data-server, tabulate, PyYAML, python-dateutil, pyparsing, pygments, pyasn1, protobuf, prompt-toolkit, promise, Pillow, pexpect, parso, oauthlib, numpy, networkx, MarkupSafe, kiwisolver, intervaltree, importlib-resources, idna, grpcio, google-pasta, gast, future, fonttools, etils, dill, cycler, cloudpickle, charset-normalizer, certifi, cachetools, attrs, asttokens, absl-py, werkzeug, tifffile, tf-slim, tensorflow-probability, stack-data, sox, scipy, rsa, requests, PyWavelets, pyasn1-modules, pretty-midi, pandas, opt-einsum, numba, matplotlib-inline, matplotlib, markdown, keras-preprocessing, Jinja2, jedi, imageio, h5py, googleapis-common-protos, dm-sonnet, contourpy, astunparse, tensorflow-metadata, sk-video, scikit-image, resampy, requests-oauthlib, mir-eval, IPython, google-auth, bokeh, tensorflow-datasets, google-auth-oauthlib, tensorboard, note-seq, tensorflow, magenta\n",
            "  Attempting uninstall: llvmlite\n",
            "    Found existing installation: llvmlite 0.40.0\n",
            "    Uninstalling llvmlite-0.40.0:\n",
            "      Successfully uninstalled llvmlite-0.40.0\n",
            "  Attempting uninstall: wheel\n",
            "    Found existing installation: wheel 0.40.0\n",
            "    Uninstalling wheel-0.40.0:\n",
            "      Successfully uninstalled wheel-0.40.0\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.23.0\n",
            "    Uninstalling numpy-1.23.0:\n",
            "      Successfully uninstalled numpy-1.23.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.10.1\n",
            "    Uninstalling scipy-1.10.1:\n",
            "      Successfully uninstalled scipy-1.10.1\n",
            "  Attempting uninstall: numba\n",
            "    Found existing installation: numba 0.57.0\n",
            "    Uninstalling numba-0.57.0:\n",
            "      Successfully uninstalled numba-0.57.0\n",
            "  Attempting uninstall: resampy\n",
            "    Found existing installation: resampy 0.4.2\n",
            "    Uninstalling resampy-0.4.2:\n",
            "      Successfully uninstalled resampy-0.4.2\n",
            "Successfully installed IPython-8.12.2 Jinja2-3.1.2 MarkupSafe-2.1.2 Pillow-9.2.0 PyWavelets-1.4.1 PyYAML-6.0 absl-py-1.2.0 asttokens-2.2.1 astunparse-1.6.3 attrs-23.1.0 backcall-0.2.0 bokeh-3.1.1 cachetools-5.3.1 certifi-2023.5.7 charset-normalizer-3.1.0 cloudpickle-2.2.1 contourpy-1.0.7 cycler-0.11.0 dill-0.3.6 dm-sonnet-2.0.0 dm-tree-0.1.8 etils-1.3.0 executing-1.2.0 flatbuffers-1.12 fonttools-4.39.4 future-0.18.3 gast-0.4.0 google-auth-2.19.1 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 googleapis-common-protos-1.59.0 grpcio-1.54.2 h5py-3.8.0 idna-3.4 imageio-2.20.0 importlib-resources-5.12.0 intervaltree-3.1.0 jedi-0.18.2 keras-2.9.0 keras-preprocessing-1.1.2 kiwisolver-1.4.4 libclang-16.0.0 llvmlite-0.32.1 magenta-2.1.4 markdown-3.4.3 matplotlib-3.5.2 matplotlib-inline-0.1.6 mido-1.2.6 mir-eval-0.7 networkx-3.1 note-seq-0.0.3 numba-0.49.1 numpy-1.21.6 oauthlib-3.2.2 opt-einsum-3.3.0 pandas-2.0.2 parso-0.8.3 pexpect-4.8.0 pickleshare-0.7.5 pretty-midi-0.2.9 promise-2.3 prompt-toolkit-3.0.38 protobuf-3.19.6 ptyprocess-0.7.0 pure-eval-0.2.2 pyasn1-0.5.0 pyasn1-modules-0.3.0 pydub-0.25.1 pygments-2.15.1 pygtrie-2.5.0 pyparsing-3.0.9 python-dateutil-2.8.2 python-rtmidi-1.1.2 pytz-2023.3 requests-2.31.0 requests-oauthlib-1.3.1 resampy-0.3.1 rsa-4.9 scikit-image-0.19.3 scipy-1.7.3 sk-video-1.1.10 sortedcontainers-2.4.0 sox-1.4.1 stack-data-0.6.2 tabulate-0.9.0 tensorboard-2.9.1 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.9.1 tensorflow-datasets-4.6.0 tensorflow-estimator-2.9.0 tensorflow-io-gcs-filesystem-0.32.0 tensorflow-metadata-1.13.0 tensorflow-probability-0.17.0 termcolor-2.3.0 tf-slim-1.1.0 tifffile-2023.4.12 toml-0.10.2 tornado-6.3.2 tqdm-4.65.0 traitlets-5.9.0 typing-extensions-4.6.3 tzdata-2023.3 urllib3-1.26.16 wcwidth-0.2.6 werkzeug-2.3.4 wheel-0.37.1 wrapt-1.15.0 xyzservices-2023.5.0\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "\u001b[0m"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "cycler",
                  "dateutil",
                  "google",
                  "kiwisolver",
                  "matplotlib_inline",
                  "pexpect",
                  "pickleshare",
                  "prompt_toolkit",
                  "wcwidth"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Install hmmlearn before downgrading Python\n",
        "!pip install hmmlearn\n",
        "\n",
        "# Downgrade Python\n",
        "!apt-get update -y\n",
        "!apt-get install python3.8\n",
        "!update-alternatives --set python3 /usr/bin/python3.8\n",
        "!curl https://bootstrap.pypa.io/get-pip.py -o get-pip.py\n",
        "!python get-pip.py\n",
        "import sys\n",
        "# This path is Colab-runtime specific, check path in other systems.\n",
        "_ = (sys.path.append(\"/usr/local/lib/python3.8/dist-packages\"))\n",
        "\n",
        "\n",
        "# Preinstall legacy packages\n",
        "!pip install numba==0.48\n",
        "!pip install numpy==1.23\n",
        "!pip install packaging>=21.3\n",
        "!pip install librosa==0.7.2\n",
        "\n",
        "# Install Magenta\n",
        "!pip install magenta"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "_6KFFCmLGmuR"
      },
      "source": [
        "# 데이터셋 전처리 (TFRecord)\n",
        "\n",
        "- 참고 : https://bcho.tistory.com/1190  \n",
        "TFRecord 파일은 tensorflow의 학습 데이터등을 저장하기 위한 바이너리 데이터 포맷으로, 구글의 Protocol Buffer 포맷으로 데이터를 파일에 Serialize하여 저장한다.\n",
        "\n",
        "1. CSV 파일에서와 같이 숫자나 텍스트 데이터를 읽을 때는 크게 지장이 없지만, 이미지 데이터를 읽을 경우 이미지는 JPEG나 PNG형태의 파일로 저장되어 있고 이에 대한 메타 데이터와 레이블은 별도의 파일에 저장되어 있기 때문에, 학습 데이터를 읽을 때 메타데이터나 레이블 파일 하나만 읽는 것이 아니라 이미지 파일도 별도로 읽어야 하기 때문에, 코드가 복잡해진다.\n",
        "\n",
        "2. 이미지를 JPG나 PNG 포맷으로 읽어서 매번 디코딩을 하게되면, 그 성능이 저하되서 학습단계에서 데이터를 읽는 부분에서 많은 성능 저하가 발생한다."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "-tMYr95tbaRn"
      },
      "outputs": [],
      "source": [
        "# 데이터셋 압축 해제\n",
        "\n",
        "import zipfile\n",
        "\n",
        "zipfile.ZipFile('/content/groove-v1.0.0-midionly.zip').extractall('groove')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "N3KVPCdxbta0",
        "outputId": "dbe5e281-5670-4a96-8083-a18e279ab69d"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-736c4a0d-57ce-4a35-a24e-1d221a189bfa\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>drummer</th>\n",
              "      <th>session</th>\n",
              "      <th>id</th>\n",
              "      <th>style</th>\n",
              "      <th>bpm</th>\n",
              "      <th>beat_type</th>\n",
              "      <th>time_signature</th>\n",
              "      <th>midi_filename</th>\n",
              "      <th>audio_filename</th>\n",
              "      <th>duration</th>\n",
              "      <th>split</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/1</td>\n",
              "      <td>funk/groove1</td>\n",
              "      <td>138</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
              "      <td>drummer1/eval_session/1_funk-groove1_138_beat_...</td>\n",
              "      <td>27.872308</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/10</td>\n",
              "      <td>soul/groove10</td>\n",
              "      <td>102</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
              "      <td>drummer1/eval_session/10_soul-groove10_102_bea...</td>\n",
              "      <td>37.691158</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/2</td>\n",
              "      <td>funk/groove2</td>\n",
              "      <td>105</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
              "      <td>drummer1/eval_session/2_funk-groove2_105_beat_...</td>\n",
              "      <td>36.351218</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/3</td>\n",
              "      <td>soul/groove3</td>\n",
              "      <td>86</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
              "      <td>drummer1/eval_session/3_soul-groove3_86_beat_4...</td>\n",
              "      <td>44.716543</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>drummer1</td>\n",
              "      <td>drummer1/eval_session</td>\n",
              "      <td>drummer1/eval_session/4</td>\n",
              "      <td>soul/groove4</td>\n",
              "      <td>80</td>\n",
              "      <td>beat</td>\n",
              "      <td>4-4</td>\n",
              "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
              "      <td>drummer1/eval_session/4_soul-groove4_80_beat_4...</td>\n",
              "      <td>47.987500</td>\n",
              "      <td>test</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-736c4a0d-57ce-4a35-a24e-1d221a189bfa')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-736c4a0d-57ce-4a35-a24e-1d221a189bfa button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-736c4a0d-57ce-4a35-a24e-1d221a189bfa');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "    drummer                session                        id          style  \\\n",
              "0  drummer1  drummer1/eval_session   drummer1/eval_session/1   funk/groove1   \n",
              "1  drummer1  drummer1/eval_session  drummer1/eval_session/10  soul/groove10   \n",
              "2  drummer1  drummer1/eval_session   drummer1/eval_session/2   funk/groove2   \n",
              "3  drummer1  drummer1/eval_session   drummer1/eval_session/3   soul/groove3   \n",
              "4  drummer1  drummer1/eval_session   drummer1/eval_session/4   soul/groove4   \n",
              "\n",
              "   bpm beat_type time_signature  \\\n",
              "0  138      beat            4-4   \n",
              "1  102      beat            4-4   \n",
              "2  105      beat            4-4   \n",
              "3   86      beat            4-4   \n",
              "4   80      beat            4-4   \n",
              "\n",
              "                                       midi_filename  \\\n",
              "0  drummer1/eval_session/1_funk-groove1_138_beat_...   \n",
              "1  drummer1/eval_session/10_soul-groove10_102_bea...   \n",
              "2  drummer1/eval_session/2_funk-groove2_105_beat_...   \n",
              "3  drummer1/eval_session/3_soul-groove3_86_beat_4...   \n",
              "4  drummer1/eval_session/4_soul-groove4_80_beat_4...   \n",
              "\n",
              "                                      audio_filename   duration split  \n",
              "0  drummer1/eval_session/1_funk-groove1_138_beat_...  27.872308  test  \n",
              "1  drummer1/eval_session/10_soul-groove10_102_bea...  37.691158  test  \n",
              "2  drummer1/eval_session/2_funk-groove2_105_beat_...  36.351218  test  \n",
              "3  drummer1/eval_session/3_soul-groove3_86_beat_4...  44.716543  test  \n",
              "4  drummer1/eval_session/4_soul-groove4_80_beat_4...  47.987500  test  "
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# info.csv (메타데이터) 확인\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "df = pd.read_csv('groove/groove/info.csv')\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nQa5OvJoGbvy",
        "outputId": "d517fdc6-ce2e-4604-8372-cf9cf3cd91fd"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/info.csv\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/LICENSE\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/README\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer1/eval_session/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer1/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer1/session3/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer1/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer8/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer8/eval_session/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer8/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer8/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer6/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer6/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer6/session3/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer6/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer2/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer2/session3/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer2/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer4/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer4/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer5/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer5/eval_session/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer5/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer5/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer7/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer7/eval_session/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer7/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer7/session3/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer7/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer10/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer10/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer3/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer3/session2/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer3/session1/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer9/Icon\n",
            "WARNING:tensorflow:Unable to find a converter for file groove/groove/drummer9/session1/Icon\n"
          ]
        }
      ],
      "source": [
        "# https://github.com/magenta/magenta/tree/main/magenta/scripts\n",
        "# 루트 디렉터리로부터 재귀적으로 순회하며 midi 파일 tfrecord로 변환 (내부적으로 convert_files() 함수 호출)\n",
        "\n",
        "from magenta.scripts.convert_dir_to_note_sequences import convert_directory\n",
        "\n",
        "convert_directory(\n",
        "    root_dir='groove/',\n",
        "    output_file='groove.tfrecord',\n",
        "    recursive=True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fwx04YUWHtR2"
      },
      "source": [
        "# 모델링"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "AixGJxjbGe1p",
        "outputId": "e4ed1d6f-68b8-46c7-a9d9-7998f03caa77"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.8/dist-packages/pretty_midi/instrument.py:167: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  if bend_int is not 0:\n",
            "/usr/local/lib/python3.8/dist-packages/pretty_midi/instrument.py:176: SyntaxWarning: \"is not\" with a literal. Did you mean \"!=\"?\n",
            "  if bend_int is not 0:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "Config(model=<magenta.models.music_vae.base_model.MusicVAE object at 0x7f16a3c5ffa0>, hparams=HParams([('batch_size', 512), ('beta_rate', 0.0), ('clip_mode', 'global_norm'), ('conditional', True), ('control_preprocessing_rnn_size', [256]), ('dec_rnn_size', [256, 256]), ('decay_rate', 0.9999), ('dropout_keep_prob', 0.3), ('enc_rnn_size', [512]), ('free_bits', 48), ('grad_clip', 1.0), ('grad_norm_clip_to_zero', 10000), ('learning_rate', 0.001), ('max_beta', 0.2), ('max_seq_len', 64), ('min_learning_rate', 1e-05), ('residual_decoder', False), ('residual_encoder', False), ('sampling_rate', 0.0), ('sampling_schedule', 'constant'), ('use_cudnn', False), ('z_size', 256)]), note_sequence_augmenter=None, data_converter=<magenta.models.music_vae.data.GrooveConverter object at 0x7f16a3be00a0>, train_examples_path=None, eval_examples_path=None, tfds_name='groove/4bar-midionly')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"\\nCONFIG_MAP['groovae_4bar'] = Config(\\n    model=MusicVAE(lstm_models.BidirectionalLstmEncoder(),\\n                   lstm_models.GrooveLstmDecoder()),\\n    hparams=merge_hparams(\\n        lstm_models.get_default_hparams(),\\n        HParams(\\n            batch_size=512,          # 배치 사이즈\\n            max_seq_len=16 * 4,      # 4 bars w/ 16 steps per bar\\n            z_size=256,              # latent dim\\n            enc_rnn_size=[512],      # 인코더 LSTM 셀의 hidden shape\\n            dec_rnn_size=[256, 256], # 디코더 LSTM 셀의 hidden shape\\n            max_beta=0.2,\\n            free_bits=48,\\n            dropout_keep_prob=0.3,   # 드롭아웃 확률\\n        )),\\n    note_sequence_augmenter=None,\\n    data_converter=data.GrooveConverter(\\n        split_bars=4, steps_per_quarter=4, quarters_per_bar=4,\\n        max_tensors_per_notesequence=20,\\n        pitch_classes=data.ROLAND_DRUM_PITCH_CLASSES,\\n        inference_pitch_classes=data.REDUCED_DRUM_PITCH_CLASSES),\\n    tfds_name='groove/4bar-midionly',\\n)\\n\""
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from magenta.models.music_vae import configs\n",
        "\n",
        "# music_vae README.md에 명시되어 있는 모델별 설정값\n",
        "config_map = configs.CONFIG_MAP\n",
        "config = config_map['groovae_4bar']\n",
        "display(config)\n",
        "\n",
        "# GrooVAE configs (magenta/models/music_vae/configs.py)\n",
        "\"\"\"\n",
        "CONFIG_MAP['groovae_4bar'] = Config(\n",
        "    model=MusicVAE(lstm_models.BidirectionalLstmEncoder(),\n",
        "                   lstm_models.GrooveLstmDecoder()),  # 4마디의 짧은 악보를 생성(?)하는 것이라 그런지.. conductor cell은 없는 것으로 추정\n",
        "    hparams=merge_hparams(\n",
        "        lstm_models.get_default_hparams(),\n",
        "        HParams(\n",
        "            batch_size=512,          # 배치 사이즈\n",
        "            max_seq_len=16 * 4,      # 4 bars w/ 16 steps per bar\n",
        "            z_size=256,              # latent dim\n",
        "            enc_rnn_size=[512],      # 인코더 LSTM 셀의 hidden shape\n",
        "            dec_rnn_size=[256, 256], # 디코더 LSTM 셀의 hidden shape\n",
        "            max_beta=0.2,            # KL term에 대한 가중치 (1보다 작을경우 샘플링 퀄리티가 좋아짐)\n",
        "            free_bits=48,\n",
        "            dropout_keep_prob=0.3,   # 드롭아웃 확률\n",
        "        )),\n",
        "    note_sequence_augmenter=None,\n",
        "    data_converter=data.GrooveConverter(\n",
        "        split_bars=4, steps_per_quarter=4, quarters_per_bar=4,\n",
        "        max_tensors_per_notesequence=20,\n",
        "        pitch_classes=data.ROLAND_DRUM_PITCH_CLASSES,\n",
        "        inference_pitch_classes=data.REDUCED_DRUM_PITCH_CLASSES),\n",
        "    tfds_name='groove/4bar-midionly',\n",
        ")\n",
        "\"\"\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W3_RwTwkHx9x"
      },
      "source": [
        "# 학습"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "Rnm2R80bGtRd"
      },
      "outputs": [],
      "source": [
        "#import tensorflow as tf\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "def _get_input_tensors(dataset, config):\n",
        "    \"\"\"Get input tensors from dataset.\"\"\"\n",
        "    batch_size = config.hparams.batch_size\n",
        "    iterator = tf.data.make_one_shot_iterator(dataset)\n",
        "    (input_sequence, output_sequence, control_sequence, sequence_length) = iterator.get_next()\n",
        "    input_sequence.set_shape(\n",
        "        [batch_size, None, config.data_converter.input_depth]\n",
        "    )\n",
        "    output_sequence.set_shape(\n",
        "          [batch_size, None, config.data_converter.output_depth]\n",
        "    )\n",
        "    if not config.data_converter.control_depth:\n",
        "        control_sequence = None\n",
        "    else:\n",
        "        control_sequence.set_shape(\n",
        "            [batch_size, None, config.data_converter.control_depth]\n",
        "        )\n",
        "    sequence_length.set_shape([batch_size] + sequence_length.shape[1:].as_list())\n",
        "\n",
        "    return {\n",
        "      'input_sequence': input_sequence,\n",
        "      'output_sequence': output_sequence,\n",
        "      'control_sequence': control_sequence,\n",
        "      'sequence_length': sequence_length\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "4FB5yCn-G0Rx"
      },
      "outputs": [],
      "source": [
        "import tf_slim \n",
        "\n",
        "def train(train_dir,\n",
        "          config,\n",
        "          dataset_fn,\n",
        "          checkpoints_to_keep=5,\n",
        "          keep_checkpoint_every_n_hours=1,\n",
        "          num_steps=None,\n",
        "          master='',\n",
        "          num_sync_workers=0,\n",
        "          num_ps_tasks=0,\n",
        "          task=0):\n",
        "    \"\"\"Train loop.\"\"\"\n",
        "    tf.gfile.MakeDirs(train_dir)\n",
        "    is_chief = (task == 0)\n",
        "        \n",
        "    with tf.Graph().as_default():\n",
        "        with tf.device(tf.train.replica_device_setter(num_ps_tasks, merge_devices=True)):\n",
        "\n",
        "            model = config.model\n",
        "            model.build(\n",
        "                config.hparams,\n",
        "                config.data_converter.output_depth,\n",
        "                is_training=True\n",
        "           )\n",
        "\n",
        "            # AdamOptimzer 사용\n",
        "            optimizer = model.train(**_get_input_tensors(dataset_fn(), config))\n",
        "\n",
        "            hooks = []\n",
        "            if num_sync_workers:\n",
        "                optimizer = tf.train.SyncReplicasOptimizer(\n",
        "                    optimizer,\n",
        "                    num_sync_workers\n",
        "                )\n",
        "                hooks.append(optimizer.make_session_run_hook(is_chief))\n",
        "\n",
        "            grads, var_list = list(zip(*optimizer.compute_gradients(model.loss)))\n",
        "            global_norm = tf.global_norm(grads)\n",
        "            tf.summary.scalar('global_norm', global_norm)\n",
        "\n",
        "            # gradient clip : gradient가 급격하기 explode하는 것을 방지하기 위해 임계치를 넘어가면 특정값으로 고정\n",
        "            if config.hparams.clip_mode == 'value':\n",
        "                g = config.hparams.grad_clip\n",
        "                clipped_grads = [tf.clip_by_value(grad, -g, g) for grad in grads]\n",
        "            elif config.hparams.clip_mode == 'global_norm':\n",
        "                clipped_grads = tf.cond(\n",
        "                    global_norm < config.hparams.grad_norm_clip_to_zero,\n",
        "                    lambda: tf.clip_by_global_norm(  # pylint:disable=g-long-lambda\n",
        "                    grads, config.hparams.grad_clip, use_norm=global_norm)[0],\n",
        "                    lambda: [tf.zeros(tf.shape(g)) for g in grads]\n",
        "                )\n",
        "            else:\n",
        "                raise ValueError(\n",
        "                    'Unknown clip_mode: {}'.format(config.hparams.clip_mode)\n",
        "                )\n",
        "            train_op = optimizer.apply_gradients(\n",
        "                list(zip(clipped_grads, var_list)),\n",
        "                global_step=model.global_step,\n",
        "                name='train_step'\n",
        "            )\n",
        "\n",
        "            logging_dict = {'global_step': model.global_step, \n",
        "                            'loss': model.loss}\n",
        "\n",
        "            hooks.append(tf.train.LoggingTensorHook(logging_dict, every_n_iter=100))\n",
        "            if num_steps:\n",
        "                hooks.append(tf.train.StopAtStepHook(last_step=num_steps))\n",
        "\n",
        "            scaffold = tf.train.Scaffold(\n",
        "                saver=tf.train.Saver(\n",
        "                max_to_keep=checkpoints_to_keep,\n",
        "                keep_checkpoint_every_n_hours=keep_checkpoint_every_n_hours)\n",
        "            )\n",
        "            tf_slim.training.train(\n",
        "                train_op=train_op,\n",
        "                logdir=train_dir,\n",
        "                scaffold=scaffold,\n",
        "                hooks=hooks,\n",
        "                save_checkpoint_secs=60,\n",
        "                master=master,\n",
        "                is_chief=is_chief\n",
        "            )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "bH89x0fLG2_G",
        "outputId": "74818253-bfda-4fe2-e5c5-e2ce626e304e"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/music_vae/train'"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 학습 가중치 저장 경로\n",
        "\n",
        "import os\n",
        "\n",
        "run_dir = os.path.expanduser('/content/music_vae/')\n",
        "train_dir = os.path.join(run_dir, 'train')\n",
        "train_dir"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GyeAc5syG4v_",
        "outputId": "3c68d4cb-1c0a-4e3f-a0a5-52bf07d36577"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "Config(model=<magenta.models.music_vae.base_model.MusicVAE object at 0x7f16a3c5ffa0>, hparams=HParams([('batch_size', 512), ('beta_rate', 0.0), ('clip_mode', 'global_norm'), ('conditional', True), ('control_preprocessing_rnn_size', [256]), ('dec_rnn_size', [256, 256]), ('decay_rate', 0.9999), ('dropout_keep_prob', 0.3), ('enc_rnn_size', [512]), ('free_bits', 48), ('grad_clip', 1.0), ('grad_norm_clip_to_zero', 10000), ('learning_rate', 0.001), ('max_beta', 0.2), ('max_seq_len', 64), ('min_learning_rate', 1e-05), ('residual_decoder', False), ('residual_encoder', False), ('sampling_rate', 0.0), ('sampling_schedule', 'constant'), ('use_cudnn', False), ('z_size', 256)]), note_sequence_augmenter=None, data_converter=<magenta.models.music_vae.data.GrooveConverter object at 0x7f16a3be00a0>, train_examples_path='/content/groove.tfrecord', eval_examples_path=None, tfds_name=None)"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# 이전에 전처리한 tfrecord를 학습에 사용하도록 설정 객체 업데이트\n",
        "\n",
        "config_update_map = {}\n",
        "config_update_map['train_examples_path'] = os.path.expanduser(\n",
        "    '/content/groove.tfrecord'\n",
        ")\n",
        "config_update_map['tfds_name'] = None\n",
        "config = configs.update_config(config, config_update_map)\n",
        "config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "mJPFEXjEHAyC"
      },
      "outputs": [],
      "source": [
        "from magenta.models.music_vae.data import get_dataset\n",
        "\n",
        "# magenta에 내장되어 있는 데이터셋 로드 함수\n",
        "# config에 명시된 train_examples_path (tfrecord)를 데이터셋화한다.\n",
        "\n",
        "def dataset_fn():\n",
        "    return get_dataset(\n",
        "        config,\n",
        "        tf_file_reader=tf.data.TFRecordDataset,\n",
        "        is_training=True,\n",
        "        cache_dataset=True\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kvo0RyhNHCUJ",
        "outputId": "dfb165c8-52e9-4859-cbfc-71fda93d4705"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/training_util.py:396: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.10/dist-packages/tensorflow/python/training/saver.py:1067: remove_checkpoint (from tensorflow.python.checkpoint.checkpoint_management) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use standard file APIs to delete files with this prefix.\n"
          ]
        }
      ],
      "source": [
        "train(\n",
        "    train_dir,\n",
        "    config=config,\n",
        "    dataset_fn=dataset_fn,\n",
        "    num_steps=1000,  # 'Number of training steps or `None` for infinite.'\n",
        ")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rG2vzm5mIcaB"
      },
      "source": [
        "# 생성"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "hqQK-uuqasMy"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 The Magenta Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"A class for sampling, encoding, and decoding from trained MusicVAE models.\"\"\"\n",
        "import copy\n",
        "import os\n",
        "import re\n",
        "import tarfile\n",
        "import tempfile\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "\n",
        "class NoExtractedExamplesError(Exception):\n",
        "  pass\n",
        "\n",
        "\n",
        "class MultipleExtractedExamplesError(Exception):\n",
        "  pass\n",
        "\n",
        "\n",
        "class TrainedModel(object):\n",
        "  \"\"\"An interface to a trained model for encoding, decoding, and sampling.\n",
        "\n",
        "  Attributes:\n",
        "    config: The Config to build the model graph with.\n",
        "    batch_size: The batch size to build the model graph with.\n",
        "    checkpoint_dir_or_path: The directory containing checkpoints for the model,\n",
        "      the most recent of which will be loaded, or a direct path to a specific\n",
        "      checkpoint.\n",
        "    var_name_substitutions: Optional list of string pairs containing regex\n",
        "      patterns and substitution values for renaming model variables to match\n",
        "      those in the checkpoint. Useful for backwards compatibility.\n",
        "    session_target: Optional execution engine to connect to. Defaults to\n",
        "      in-process.\n",
        "    sample_kwargs: Additional, non-tensor keyword arguments to pass to sample\n",
        "      call.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, config, batch_size, checkpoint_dir_or_path=None,\n",
        "               var_name_substitutions=None, session_target='', **sample_kwargs):\n",
        "    if tf.gfile.IsDirectory(checkpoint_dir_or_path):\n",
        "      checkpoint_path = tf.train.latest_checkpoint(checkpoint_dir_or_path)\n",
        "    else:\n",
        "      checkpoint_path = checkpoint_dir_or_path\n",
        "    # self._config = copy.deepcopy(config)\n",
        "    self._config = config  # deepcopy 오류로 인해 수정\n",
        "    self._config.data_converter.set_mode('infer')\n",
        "    self._config.hparams.batch_size = batch_size\n",
        "    with tf.Graph().as_default():\n",
        "      model = self._config.model\n",
        "      model.build(\n",
        "          self._config.hparams,\n",
        "          self._config.data_converter.output_depth,\n",
        "          is_training=False)\n",
        "      # Input placeholders\n",
        "      self._temperature = tf.placeholder(tf.float32, shape=())\n",
        "\n",
        "      if self._config.hparams.z_size:\n",
        "        self._z_input = tf.placeholder(\n",
        "            tf.float32, shape=[batch_size, self._config.hparams.z_size])\n",
        "      else:\n",
        "        self._z_input = None\n",
        "\n",
        "      if self._config.data_converter.control_depth > 0:\n",
        "        self._c_input = tf.placeholder(\n",
        "            tf.float32, shape=[None, self._config.data_converter.control_depth])\n",
        "      else:\n",
        "        self._c_input = None\n",
        "\n",
        "      self._inputs = tf.placeholder(\n",
        "          tf.float32,\n",
        "          shape=[batch_size, None, self._config.data_converter.input_depth])\n",
        "      self._controls = tf.placeholder(\n",
        "          tf.float32,\n",
        "          shape=[batch_size, None, self._config.data_converter.control_depth])\n",
        "      self._inputs_length = tf.placeholder(\n",
        "          tf.int32,\n",
        "          shape=[batch_size] + list(self._config.data_converter.length_shape))\n",
        "      self._max_length = tf.placeholder(tf.int32, shape=())\n",
        "      # Outputs\n",
        "      self._outputs, self._decoder_results = model.sample(\n",
        "          batch_size,\n",
        "          max_length=self._max_length,\n",
        "          z=self._z_input,\n",
        "          c_input=self._c_input,\n",
        "          temperature=self._temperature,\n",
        "          **sample_kwargs)\n",
        "      if self._config.hparams.z_size:\n",
        "        q_z = model.encode(self._inputs, self._inputs_length, self._controls)\n",
        "        self._mu = q_z.loc\n",
        "        self._sigma = q_z.scale.diag\n",
        "        self._z = q_z.sample()\n",
        "\n",
        "      var_map = None\n",
        "      if var_name_substitutions is not None:\n",
        "        var_map = {}\n",
        "        for v in tf.global_variables():\n",
        "          var_name = v.name[:-2]  # Strip ':0' suffix.\n",
        "          for pattern, substitution in var_name_substitutions:\n",
        "            var_name = re.sub(pattern, substitution, var_name)\n",
        "          if var_name != v.name[:-2]:\n",
        "            tf.logging.info('Renaming `%s` to `%s`.', v.name[:-2], var_name)\n",
        "          var_map[var_name] = v\n",
        "\n",
        "      # Restore graph\n",
        "      self._sess = tf.Session(target=session_target)\n",
        "      saver = tf.train.Saver(var_map)\n",
        "      if (os.path.exists(checkpoint_path) and\n",
        "          tarfile.is_tarfile(checkpoint_path)):\n",
        "        tf.logging.info('Unbundling checkpoint.')\n",
        "        with tempfile.TemporaryDirectory() as temp_dir:\n",
        "          tar = tarfile.open(checkpoint_path)\n",
        "          tar.extractall(temp_dir)\n",
        "          # Assume only a single checkpoint is in the directory.\n",
        "          for name in tar.getnames():\n",
        "            if name.endswith('.index'):\n",
        "              checkpoint_path = os.path.join(temp_dir, name[0:-6])\n",
        "              break\n",
        "          saver.restore(self._sess, checkpoint_path)\n",
        "      else:\n",
        "        saver.restore(self._sess, checkpoint_path)\n",
        "\n",
        "  def sample(self, n=None, length=None, temperature=1.0, same_z=False,\n",
        "             c_input=None):\n",
        "    \"\"\"Generates random samples from the model.\n",
        "\n",
        "    Args:\n",
        "      n: The number of samples to return. A full batch will be returned if not\n",
        "        specified.\n",
        "      length: The maximum length of a sample in decoder iterations. Required\n",
        "        if end tokens are not being used.\n",
        "      temperature: The softmax temperature to use (if applicable).\n",
        "      same_z: Whether to use the same latent vector for all samples in the\n",
        "        batch (if applicable).\n",
        "      c_input: A sequence of control inputs to use for all samples (if\n",
        "        applicable).\n",
        "    Returns:\n",
        "      A list of samples as NoteSequence objects.\n",
        "    Raises:\n",
        "      ValueError: If `length` is not specified and an end token is not being\n",
        "        used.\n",
        "    \"\"\"\n",
        "    batch_size = self._config.hparams.batch_size\n",
        "    n = n or batch_size\n",
        "    z_size = self._config.hparams.z_size\n",
        "\n",
        "    if not length and self._config.data_converter.end_token is None:\n",
        "      raise ValueError(\n",
        "          'A length must be specified when the end token is not used.')\n",
        "    length = length or tf.int32.max\n",
        "\n",
        "    feed_dict = {\n",
        "        self._temperature: temperature,\n",
        "        self._max_length: length\n",
        "    }\n",
        "\n",
        "    if self._z_input is not None and same_z:\n",
        "      z = np.random.randn(z_size).astype(np.float32)\n",
        "      z = np.tile(z, (batch_size, 1))\n",
        "      feed_dict[self._z_input] = z\n",
        "\n",
        "    if self._c_input is not None:\n",
        "      feed_dict[self._c_input] = c_input\n",
        "\n",
        "    outputs = []\n",
        "    for _ in range(int(np.ceil(n / batch_size))):\n",
        "      if self._z_input is not None and not same_z:\n",
        "        feed_dict[self._z_input] = (\n",
        "            np.random.randn(batch_size, z_size).astype(np.float32))\n",
        "      outputs.append(self._sess.run(self._outputs, feed_dict))\n",
        "    samples = np.vstack(outputs)[:n]\n",
        "    if self._c_input is not None:\n",
        "      return self._config.data_converter.from_tensors(\n",
        "          samples, np.tile(np.expand_dims(c_input, 0), [batch_size, 1, 1]))\n",
        "    else:\n",
        "      return self._config.data_converter.from_tensors(samples)\n",
        "\n",
        "  def encode(self, note_sequences, assert_same_length=False):\n",
        "    \"\"\"Encodes a collection of NoteSequences into latent vectors.\n",
        "\n",
        "    Args:\n",
        "      note_sequences: A collection of NoteSequence objects to encode.\n",
        "      assert_same_length: Whether to raise an AssertionError if all of the\n",
        "        extracted sequences are not the same length.\n",
        "    Returns:\n",
        "      The encoded `z`, `mu`, and `sigma` values.\n",
        "    Raises:\n",
        "      RuntimeError: If called for a non-conditional model.\n",
        "      NoExtractedExamplesError: If no examples were extracted.\n",
        "      MultipleExtractedExamplesError: If multiple examples were extracted.\n",
        "      AssertionError: If `assert_same_length` is True and any extracted\n",
        "        sequences differ in length.\n",
        "    \"\"\"\n",
        "    if not self._config.hparams.z_size:\n",
        "      raise RuntimeError('Cannot encode with a non-conditional model.')\n",
        "\n",
        "    inputs = []\n",
        "    controls = []\n",
        "    lengths = []\n",
        "    for note_sequence in note_sequences:\n",
        "      extracted_tensors = self._config.data_converter.to_tensors(note_sequence)\n",
        "      if not extracted_tensors.inputs:\n",
        "        raise NoExtractedExamplesError(\n",
        "            'No examples extracted from NoteSequence: %s' % note_sequence)\n",
        "      if len(extracted_tensors.inputs) > 1:\n",
        "        raise MultipleExtractedExamplesError(\n",
        "            'Multiple (%d) examples extracted from NoteSequence: %s' %\n",
        "            (len(extracted_tensors.inputs), note_sequence))\n",
        "      inputs.append(extracted_tensors.inputs[0])\n",
        "      controls.append(extracted_tensors.controls[0])\n",
        "      lengths.append(extracted_tensors.lengths[0])\n",
        "      if assert_same_length and len(inputs[0]) != len(inputs[-1]):\n",
        "        raise AssertionError(\n",
        "            'Sequences 0 and %d have different lengths: %d vs %d' %\n",
        "            (len(inputs) - 1, len(inputs[0]), len(inputs[-1])))\n",
        "    return self.encode_tensors(inputs, lengths, controls)\n",
        "\n",
        "  def encode_tensors(self, input_tensors, lengths, control_tensors=None):\n",
        "    \"\"\"Encodes a collection of input tensors into latent vectors.\n",
        "\n",
        "    Args:\n",
        "      input_tensors: Collection of input tensors to encode.\n",
        "      lengths: Collection of lengths of input tensors.\n",
        "      control_tensors: Collection of control tensors to encode.\n",
        "    Returns:\n",
        "      The encoded `z`, `mu`, and `sigma` values.\n",
        "    Raises:\n",
        "       RuntimeError: If called for a non-conditional model.\n",
        "    \"\"\"\n",
        "    if not self._config.hparams.z_size:\n",
        "      raise RuntimeError('Cannot encode with a non-conditional model.')\n",
        "\n",
        "    n = len(input_tensors)\n",
        "    input_depth = self._config.data_converter.input_depth\n",
        "    batch_size = self._config.hparams.batch_size\n",
        "\n",
        "    batch_pad_amt = -n % batch_size\n",
        "    if batch_pad_amt > 0:\n",
        "      input_tensors += [np.zeros([0, input_depth])] * batch_pad_amt\n",
        "    length_array = np.array(lengths, np.int32)\n",
        "    length_array = np.pad(\n",
        "        length_array,\n",
        "        [(0, batch_pad_amt)] + [(0, 0)] * (length_array.ndim - 1),\n",
        "        'constant')\n",
        "\n",
        "    max_length = max([len(t) for t in input_tensors])\n",
        "    inputs_array = np.zeros(\n",
        "        [len(input_tensors), max_length, input_depth])\n",
        "    for i, t in enumerate(input_tensors):\n",
        "      inputs_array[i, :len(t)] = t\n",
        "\n",
        "    control_depth = self._config.data_converter.control_depth\n",
        "    controls_array = np.zeros(\n",
        "        [len(input_tensors), max_length, control_depth])\n",
        "    if control_tensors is not None:\n",
        "      control_tensors += [np.zeros([0, control_depth])] * batch_pad_amt\n",
        "      for i, t in enumerate(control_tensors):\n",
        "        controls_array[i, :len(t)] = t\n",
        "\n",
        "    outputs = []\n",
        "    for i in range(len(inputs_array) // batch_size):\n",
        "      batch_begin = i * batch_size\n",
        "      batch_end = (i+1) * batch_size\n",
        "      feed_dict = {self._inputs: inputs_array[batch_begin:batch_end],\n",
        "                   self._controls: controls_array[batch_begin:batch_end],\n",
        "                   self._inputs_length: length_array[batch_begin:batch_end]}\n",
        "      outputs.append(\n",
        "          self._sess.run([self._z, self._mu, self._sigma], feed_dict))\n",
        "    assert outputs\n",
        "    return tuple(np.vstack(v)[:n] for v in zip(*outputs))\n",
        "\n",
        "  def decode(self, z, length=None, temperature=1.0, c_input=None):\n",
        "    \"\"\"Decodes a collection of latent vectors into NoteSequences.\n",
        "\n",
        "    Args:\n",
        "      z: A collection of latent vectors to decode.\n",
        "      length: The maximum length of a sample in decoder iterations. Required\n",
        "        if end tokens are not being used.\n",
        "      temperature: The softmax temperature to use (if applicable).\n",
        "      c_input: Control sequence (if applicable).\n",
        "    Returns:\n",
        "      A list of decodings as NoteSequence objects.\n",
        "    Raises:\n",
        "      RuntimeError: If called for a non-conditional model.\n",
        "      ValueError: If `length` is not specified and an end token is not being\n",
        "        used.\n",
        "    \"\"\"\n",
        "    tensors = self.decode_to_tensors(z, length, temperature, c_input)\n",
        "    if self._c_input is not None:\n",
        "      return self._config.data_converter.from_tensors(\n",
        "          tensors,\n",
        "          np.tile(\n",
        "              np.expand_dims(c_input, 0),\n",
        "              [self._config.hparams.batch_size, 1, 1]))\n",
        "    else:\n",
        "      return self._config.data_converter.from_tensors(tensors)\n",
        "\n",
        "  def decode_to_tensors(self, z, length=None, temperature=1.0, c_input=None,\n",
        "                        return_full_results=False):\n",
        "    \"\"\"Decodes a collection of latent vectors into output tensors.\n",
        "\n",
        "    Args:\n",
        "      z: A collection of latent vectors to decode.\n",
        "      length: The maximum length of a sample in decoder iterations. Required\n",
        "        if end tokens are not being used.\n",
        "      temperature: The softmax temperature to use (if applicable).\n",
        "      c_input: Control sequence (if applicable).\n",
        "      return_full_results: If true will return the full decoder_results,\n",
        "        otherwise it will return only the samples.\n",
        "    Returns:\n",
        "      If return_full_results is True, will return the full decoder_results list,\n",
        "      otherwise it will return the samples from the decoder as a 2D numpy array.\n",
        "    Raises:\n",
        "      RuntimeError: If called for a non-conditional model.\n",
        "      ValueError: If `length` is not specified and an end token is not being\n",
        "        used.\n",
        "    \"\"\"\n",
        "    if not self._config.hparams.z_size:\n",
        "      raise RuntimeError('Cannot decode with a non-conditional model.')\n",
        "\n",
        "    if not length and self._config.data_converter.end_token is None:\n",
        "      raise ValueError(\n",
        "          'A length must be specified when the end token is not used.')\n",
        "    batch_size = self._config.hparams.batch_size\n",
        "    n = len(z)\n",
        "    length = length or tf.int32.max\n",
        "\n",
        "    batch_pad_amt = -n % batch_size\n",
        "    z = np.pad(z, [(0, batch_pad_amt), (0, 0)], mode='constant')\n",
        "\n",
        "    outputs = []\n",
        "    for i in range(len(z) // batch_size):\n",
        "      feed_dict = {\n",
        "          self._temperature: temperature,\n",
        "          self._z_input: z[i*batch_size:(i+1)*batch_size],\n",
        "          self._max_length: length,\n",
        "      }\n",
        "      if self._c_input is not None:\n",
        "        feed_dict[self._c_input] = c_input\n",
        "      if return_full_results:\n",
        "        outputs.extend(self._sess.run(self._decoder_results, feed_dict))\n",
        "      else:\n",
        "        outputs.extend(self._sess.run(self._outputs, feed_dict))\n",
        "    return outputs[:n]\n",
        "\n",
        "  def interpolate(self, start_sequence, end_sequence, num_steps,\n",
        "                  length=None, temperature=1.0, assert_same_length=True):\n",
        "    \"\"\"Interpolates between a start and an end NoteSequence.\n",
        "\n",
        "    Args:\n",
        "      start_sequence: The NoteSequence to interpolate from.\n",
        "      end_sequence: The NoteSequence to interpolate to.\n",
        "      num_steps: Number of NoteSequences to be generated, including the\n",
        "        reconstructions of the start and end sequences.\n",
        "      length: The maximum length of a sample in decoder iterations. Required\n",
        "        if end tokens are not being used.\n",
        "      temperature: The softmax temperature to use (if applicable).\n",
        "      assert_same_length: Whether to raise an AssertionError if all of the\n",
        "        extracted sequences are not the same length.\n",
        "    Returns:\n",
        "      A list of interpolated NoteSequences.\n",
        "    Raises:\n",
        "      AssertionError: If `assert_same_length` is True and any extracted\n",
        "        sequences differ in length.\n",
        "    \"\"\"\n",
        "    def _slerp(p0, p1, t):\n",
        "      \"\"\"Spherical linear interpolation.\"\"\"\n",
        "      omega = np.arccos(np.dot(np.squeeze(p0/np.linalg.norm(p0)),\n",
        "                               np.squeeze(p1/np.linalg.norm(p1))))\n",
        "      so = np.sin(omega)\n",
        "      return np.sin((1.0-t)*omega) / so * p0 + np.sin(t*omega)/so * p1\n",
        "\n",
        "    _, mu, _ = self.encode([start_sequence, end_sequence], assert_same_length)\n",
        "    z = np.array([_slerp(mu[0], mu[1], t)\n",
        "                  for t in np.linspace(0, 1, num_steps)])\n",
        "    return self.decode(\n",
        "        length=length,\n",
        "        z=z,\n",
        "        temperature=temperature)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "KHrNTKAIHDyn"
      },
      "outputs": [],
      "source": [
        "# Copyright 2023 The Magenta Authors.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License.\n",
        "\n",
        "\"\"\"MusicVAE generation script.\"\"\"\n",
        "\n",
        "# TODO(adarob): Add support for models with conditioning.\n",
        "\n",
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "\n",
        "from magenta.models.music_vae import configs\n",
        "# from magenta.models.music_vae import TrainedModel\n",
        "import note_seq\n",
        "import numpy as np\n",
        "import tensorflow.compat.v1 as tf\n",
        "\n",
        "\n",
        "logging = tf.logging\n",
        "run_dir = '/content/music_vae'\n",
        "output_dir = '/content/music_vae/generated'\n",
        "num_outputs = 5\n",
        "max_batch_size = 8\n",
        "temperature = 0.5\n",
        "\n",
        "\n",
        "def run(config_map):\n",
        "    \"\"\"Load model params, save config file and start trainer.\n",
        "\n",
        "    Args:\n",
        "      config_map: Dictionary mapping configuration name to Config object.\n",
        "\n",
        "    Raises:\n",
        "      ValueError: if required flags are missing or invalid.\n",
        "    \"\"\"\n",
        "    config = config_map['groovae_4bar']\n",
        "    date_and_time = time.strftime('%Y-%m-%d_%H%M%S')\n",
        "    config.data_converter.max_tensors_per_item = None\n",
        "\n",
        "    logging.info('Loading model...')\n",
        "    checkpoint_dir_or_path = os.path.expanduser(\n",
        "        os.path.join(run_dir, 'train')\n",
        "    )\n",
        "    # pre-trained model weight\n",
        "    # checkpoint_dir_or_path = os.path.expanduser(\n",
        "    #     'groovae_4bar.tar'\n",
        "    # )\n",
        "    # 학습된 모델 가중치 체크포인트(.ckpt)가 저장된 경로를 인자로 넘겨 모델 로드\n",
        "    model = TrainedModel(\n",
        "      config, \n",
        "      batch_size=min(max_batch_size, num_outputs),\n",
        "      checkpoint_dir_or_path=checkpoint_dir_or_path\n",
        "    )\n",
        "\n",
        "    # 모델을 통해 확률 분포 공간으로부터 노트 샘플링\n",
        "    logging.info('Sampling...')\n",
        "    results = model.sample(\n",
        "        n=num_outputs,\n",
        "        length=config.hparams.max_seq_len,\n",
        "        temperature=temperature)\n",
        "\n",
        "    basename = os.path.join(\n",
        "      output_dir,\n",
        "      '%s_%s-*-of-%03d.mid' %\n",
        "      ('sample', date_and_time, num_outputs))\n",
        "    logging.info('Outputting %d files as `%s`...', num_outputs, basename)\n",
        "    # 노트 시퀀스 미디 파일(.mid)로 변환\n",
        "    for i, ns in enumerate(results):\n",
        "        note_seq.sequence_proto_to_midi_file(ns, basename.replace('*', '%03d' % i))\n",
        "\n",
        "    logging.info('Done.')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yOblnYx2Pc2X",
        "outputId": "e3064008-e85e-4f06-e749-aad2acef9da4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n",
            "WARNING:tensorflow:`tf.nn.rnn_cell.MultiRNNCell` is deprecated. This class is equivalent as `tf.keras.layers.StackedRNNCells`, and will be replaced by that in Tensorflow 2.0.\n"
          ]
        }
      ],
      "source": [
        "run(config_map)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "syfmTpSja1uU",
        "outputId": "4b201f67-7ac2-46d2-859c-745b8bee1552"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tar: Removing leading `/' from member names\n",
            "/content/music_vae/\n",
            "/content/music_vae/generated/\n",
            "/content/music_vae/generated/sample_2023-06-02_140601-002-of-005.mid\n",
            "/content/music_vae/generated/sample_2023-06-02_140601-003-of-005.mid\n",
            "/content/music_vae/generated/sample_2023-06-02_140601-001-of-005.mid\n",
            "/content/music_vae/generated/sample_2023-06-02_140601-000-of-005.mid\n",
            "/content/music_vae/generated/sample_2023-06-02_140601-004-of-005.mid\n",
            "/content/music_vae/.ipynb_checkpoints/\n",
            "/content/music_vae/train/\n",
            "/content/music_vae/train/model.ckpt-758.meta\n",
            "/content/music_vae/train/model.ckpt-1000.meta\n",
            "/content/music_vae/train/model.ckpt-758.data-00000-of-00001\n",
            "/content/music_vae/train/model.ckpt-483.index\n",
            "/content/music_vae/train/model.ckpt-758.index\n",
            "/content/music_vae/train/model.ckpt-899.data-00000-of-00001\n",
            "/content/music_vae/train/model.ckpt-899.index\n",
            "/content/music_vae/train/model.ckpt-1000.index\n",
            "/content/music_vae/train/.ipynb_checkpoints/\n",
            "/content/music_vae/train/model.ckpt-1000.data-00000-of-00001\n",
            "/content/music_vae/train/model.ckpt-483.meta\n",
            "/content/music_vae/train/model.ckpt-899.meta\n",
            "/content/music_vae/train/model.ckpt-483.data-00000-of-00001\n",
            "/content/music_vae/train/graph.pbtxt\n",
            "/content/music_vae/train/events.out.tfevents.1685713517.487ee473d017\n",
            "/content/music_vae/train/model.ckpt-619.index\n",
            "/content/music_vae/train/model.ckpt-619.data-00000-of-00001\n",
            "/content/music_vae/train/model.ckpt-619.meta\n",
            "/content/music_vae/train/checkpoint\n"
          ]
        }
      ],
      "source": [
        "!tar -zcvf music_vae.tar.gz /content/music_vae/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
